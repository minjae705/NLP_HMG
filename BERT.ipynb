{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOJj6+8MVYspZ0Wj32P62oT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d709c03cde8c4e41836b10fc4d4a9500":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_47f2ea9a9f3241a69b0d0b78f1377d5d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_45bbedfbddde44ac83335db957c73c42","IPY_MODEL_0a1a4b9e4eb1421882ba1b7e7dbe87bd"]}},"47f2ea9a9f3241a69b0d0b78f1377d5d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"45bbedfbddde44ac83335db957c73c42":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1e8be606c1aa40f0b5f04ebf3b164974","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7cb7bbd8a7934952802b082cd8b39498"}},"0a1a4b9e4eb1421882ba1b7e7dbe87bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7ccd1de076514bb69f997192aa64a35c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 2.03MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a975ed9aa44f4d08afc29011b75bc9dc"}},"1e8be606c1aa40f0b5f04ebf3b164974":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7cb7bbd8a7934952802b082cd8b39498":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ccd1de076514bb69f997192aa64a35c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a975ed9aa44f4d08afc29011b75bc9dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2342aa2bfdb9400c949c70ca55d95405":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_88278cffb6bf42389ca158728334e77e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_03e14af30f3541b7aa6c402c14b0cbbf","IPY_MODEL_4b1f456ace7b48fb88b207e809683df0"]}},"88278cffb6bf42389ca158728334e77e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03e14af30f3541b7aa6c402c14b0cbbf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2ff4a0d6655d4bdabe6b3f9f7f9e15da","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c65824a84cfc4db0ab66f523418de49a"}},"4b1f456ace7b48fb88b207e809683df0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41ee3f8dd81e491c9b2079fd3e0398d3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [04:36&lt;00:00, 2.26B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aab2bd2c33d949bb9dd0ef822b31328f"}},"2ff4a0d6655d4bdabe6b3f9f7f9e15da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c65824a84cfc4db0ab66f523418de49a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41ee3f8dd81e491c9b2079fd3e0398d3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aab2bd2c33d949bb9dd0ef822b31328f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d4e98c4cb574c9fb2f59ede96ae5fb2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_42322deb53ce4ccbaa73f965b985de44","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e041b0ca61524ada8fe8f72e46528b1c","IPY_MODEL_d7550ac46fb540aaa5ae94b13ff998a9"]}},"42322deb53ce4ccbaa73f965b985de44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e041b0ca61524ada8fe8f72e46528b1c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_746abdf231f54bbea35bcd63e9462f59","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e4bce99aa1d848769473687a8e1238e6"}},"d7550ac46fb540aaa5ae94b13ff998a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c9eb6f9645e94e329df0f90a5f884d13","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [04:35&lt;00:00, 2.59MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_783a3f40c7af426db4c251c9d6cb5952"}},"746abdf231f54bbea35bcd63e9462f59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e4bce99aa1d848769473687a8e1238e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c9eb6f9645e94e329df0f90a5f884d13":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"783a3f40c7af426db4c251c9d6cb5952":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"WCIRe77pjZd5"},"source":["## 설치 준비 데이터로드"]},{"cell_type":"code","metadata":{"id":"CaXFmYakhnhK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606547838319,"user_tz":-540,"elapsed":7314,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"126df73b-88f9-4b6e-d297-c306946699b5"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n","\r\u001b[K     |▎                               | 10kB 18.4MB/s eta 0:00:01\r\u001b[K     |▌                               | 20kB 19.8MB/s eta 0:00:01\r\u001b[K     |▊                               | 30kB 15.0MB/s eta 0:00:01\r\u001b[K     |█                               | 40kB 13.9MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51kB 10.6MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61kB 10.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71kB 11.6MB/s eta 0:00:01\r\u001b[K     |██                              | 81kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92kB 10.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102kB 10.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112kB 10.1MB/s eta 0:00:01\r\u001b[K     |███                             | 122kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 143kB 10.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153kB 10.1MB/s eta 0:00:01\r\u001b[K     |████                            | 163kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▎                           | 174kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 184kB 10.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 204kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 215kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 225kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 245kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 256kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 266kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 286kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 296kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 317kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 327kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 337kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 348kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 358kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 368kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 378kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 389kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 399kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 409kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 419kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 430kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 440kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 450kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 460kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 471kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 481kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 491kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 501kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 512kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 522kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 532kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 542kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 552kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 563kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 573kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 583kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 593kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 604kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 614kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 624kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 634kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 645kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 655kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 665kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 675kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 686kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 696kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 706kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 716kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 737kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 747kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 757kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 768kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 778kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 788kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 798kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 808kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 819kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 829kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 839kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 849kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 860kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 870kB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 880kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 890kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 901kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 911kB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 921kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 931kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 942kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 952kB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 962kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 972kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 983kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 993kB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.1MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 10.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3MB 10.1MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Collecting sentencepiece==0.1.91\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 41.0MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers==0.9.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 50.6MB/s \n","\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 42.0MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.11.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=52f7ce5400ba64213c56420f707660b071df36ed210255a2f7e413ae39def469\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IFKgHtpvhGht","executionInfo":{"status":"ok","timestamp":1606547847212,"user_tz":-540,"elapsed":6684,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["import tensorflow as tf\n","import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"XgiYEK5phhhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606547859552,"user_tz":-540,"elapsed":902,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"bca5f303-6900-4060-c079-aefbdfae485d"},"source":["# 네이버 영화리뷰 감정분석 데이터\n","!git clone https://github.com/e9t/nsmc.git"],"execution_count":4,"outputs":[{"output_type":"stream","text":["fatal: destination path 'nsmc' already exists and is not an empty directory.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JvMrmIoMiQsZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606547860171,"user_tz":-540,"elapsed":1510,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"2150e8eb-d5fc-4f80-c2e1-f02d68604a99"},"source":["# 훈련셋 150000개 테스트셋 50000개\n","train = pd.read_csv(\"nsmc/ratings_train.txt\", sep=\"\\t\")\n","test = pd.read_csv(\"nsmc/ratings_test.txt\", sep=\"\\t\")\n","\n","print(train.shape)\n","print(test.shape)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["(150000, 3)\n","(50000, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oNycVUyainVJ","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1606547860173,"user_tz":-540,"elapsed":1503,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"3f1080ea-48e8-4848-ca9a-c28753c80337"},"source":["# id 회원정보 / document 리뷰 문장 / label 긍정1 부정0\n","train.sample(10)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>document</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>149203</th>\n","      <td>8540108</td>\n","      <td>영화 운동하는 캐릭터 중에 록키가 제일 착해서 맘에 드네유.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>108805</th>\n","      <td>5367134</td>\n","      <td>정말 최고였다</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>134165</th>\n","      <td>8679096</td>\n","      <td>옛날 그때는 국민학교 로 부르던 시절 ,, 영화 속 학교 풍경 책,걸상 책가방 학생...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>99636</th>\n","      <td>9558427</td>\n","      <td>'하이틴 로맨스 판타지 SF'는 이제 금물로 했으면.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27407</th>\n","      <td>7936437</td>\n","      <td>왜 평점 0점은 없죠? 감독은 왜 한국인이 보는 영화에 한국인을 이렇게 비하 하는 ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>86733</th>\n","      <td>9652213</td>\n","      <td>성지순례하러 왔습니다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>29186</th>\n","      <td>10244027</td>\n","      <td>여태 본 영화중에 최최악영화.. 웃긴요소는 많이 넣은 것 같은데 하나도 안 웃기고 ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>35840</th>\n","      <td>10110252</td>\n","      <td>이렇게 괜찮은영화가 왜 평점이이러지...먹먹하지만 좋은영화라고 생각한다</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>112126</th>\n","      <td>8206840</td>\n","      <td>정말지루하고재미없고잠오는영화///</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>69219</th>\n","      <td>9556018</td>\n","      <td>그닥 재미 없음....</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              id                                           document  label\n","149203   8540108                  영화 운동하는 캐릭터 중에 록키가 제일 착해서 맘에 드네유.      1\n","108805   5367134                                            정말 최고였다      1\n","134165   8679096  옛날 그때는 국민학교 로 부르던 시절 ,, 영화 속 학교 풍경 책,걸상 책가방 학생...      1\n","99636    9558427                      '하이틴 로맨스 판타지 SF'는 이제 금물로 했으면.      0\n","27407    7936437  왜 평점 0점은 없죠? 감독은 왜 한국인이 보는 영화에 한국인을 이렇게 비하 하는 ...      0\n","86733    9652213                                        성지순례하러 왔습니다      0\n","29186   10244027  여태 본 영화중에 최최악영화.. 웃긴요소는 많이 넣은 것 같은데 하나도 안 웃기고 ...      0\n","35840   10110252            이렇게 괜찮은영화가 왜 평점이이러지...먹먹하지만 좋은영화라고 생각한다      1\n","112126   8206840                                 정말지루하고재미없고잠오는영화///      0\n","69219    9556018                                       그닥 재미 없음....      0"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"ZEHgb24hjNqD"},"source":["## 훈련셋 전처리"]},{"cell_type":"code","metadata":{"id":"2DoXGVnGjSLG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606547860175,"user_tz":-540,"elapsed":1495,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"ac1602c8-4a8f-42d2-ee5c-71e8037a514a"},"source":["#리뷰 문장 추출\n","sentences = train['document']\n","sentences[:10]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                  아 더빙.. 진짜 짜증나네요 목소리\n","1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n","2                                    너무재밓었다그래서보는것을추천한다\n","3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n","4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n","5        막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.\n","6                                원작의 긴장감을 제대로 살려내지못했다.\n","7    별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단...\n","8                               액션이 없는데도 재미 있는 몇안되는 영화\n","9        왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나?\n","Name: document, dtype: object"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"X0aluxU2jgq1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606547860176,"user_tz":-540,"elapsed":1486,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"d1d2c1a7-865e-498f-f4b1-a33383df1d19"},"source":["# BERT의 입력 형식에 맞게 변환\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]',\n"," '[CLS] 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나 [SEP]',\n"," '[CLS] 너무재밓었다그래서보는것을추천한다 [SEP]',\n"," '[CLS] 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정 [SEP]',\n"," '[CLS] 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다 [SEP]',\n"," '[CLS] 막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움. [SEP]',\n"," '[CLS] 원작의 긴장감을 제대로 살려내지못했다. [SEP]',\n"," '[CLS] 별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네 [SEP]',\n"," '[CLS] 액션이 없는데도 재미 있는 몇안되는 영화 [SEP]',\n"," '[CLS] 왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나? [SEP]']"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"markdown","metadata":{"id":"S0lAHCVz-Mm-"},"source":["BERT는 Classification을 뜻하는 [CLS] 심볼이 문장의 가장 앞에 삽입된다. 파인튜닝시 출력에서 이 위치의 값을 사용하여 분류를 한다. [SEP]는 Seperation으로 두 문장을 구분하는 역할을 한다."]},{"cell_type":"code","metadata":{"id":"AGokiITFjyYv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606547860177,"user_tz":-540,"elapsed":1480,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"27d83c88-2b6b-427a-8fbf-b2e0d4982c57"},"source":["#라벨 추출\n","labels = train['label'].values\n","labels"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 0, ..., 0, 1, 0])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":122,"referenced_widgets":["d709c03cde8c4e41836b10fc4d4a9500","47f2ea9a9f3241a69b0d0b78f1377d5d","45bbedfbddde44ac83335db957c73c42","0a1a4b9e4eb1421882ba1b7e7dbe87bd","1e8be606c1aa40f0b5f04ebf3b164974","7cb7bbd8a7934952802b082cd8b39498","7ccd1de076514bb69f997192aa64a35c","a975ed9aa44f4d08afc29011b75bc9dc"]},"id":"LW8iHOeY9qSS","executionInfo":{"status":"ok","timestamp":1606547887849,"user_tz":-540,"elapsed":29145,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"6dd64e75-b61a-4213-88b3-ec7d547b0d25"},"source":["#BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print(sentences[0])\n","print(tokenized_texts[0])"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d709c03cde8c4e41836b10fc4d4a9500","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","[CLS] 아 더빙.. 진짜 짜증나네요 목소리 [SEP]\n","['[CLS]', '아', '더', '##빙', '.', '.', '진', '##짜', '짜', '##증', '##나', '##네', '##요', '목', '##소', '##리', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Eu9EoD69-sSG"},"source":["BERT는 형태소분석으로 토큰을 분리하지 않고 WordPiece라는 통계적인 방식을 사용한다. 한 단어 내에서 자주 나오는 글자들을 붙여 하나의 토큰으로 만든다. 이렇게하면 언어에 상관없이 토큰을 생성할 수 있고, 신조어같이 사전에 없는 단어들을 처리하기에 좋다.\n","\\##은 앞 토큰과 이어진다는 표시이다. 토크나이저는 여러 언어의 데이터를 기반으로 만든 'bert-base-multilingual-cased'를 사용한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qtrytzsZ-Eem","executionInfo":{"status":"ok","timestamp":1606547892492,"user_tz":-540,"elapsed":33781,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"3a7e2638-7f1e-4cd4-e3d1-a324226dc40f"},"source":["#입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","#토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","#문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([   101,   9519,   9074, 119005,    119,    119,   9708, 119235,\n","         9715, 119230,  16439,  77884,  48549,   9284,  22333,  12692,\n","          102,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0,\n","            0,      0,      0,      0,      0,      0,      0,      0])"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"mheu1z93_sQF"},"source":["딥러닝 모델에 토큰 자체를 입력으로 넣을 수 없다. 임베딩 레이어에는 토큰을 숫자로 된 인덱스로 변환하여 사용한다. BERT의 토크나이저는 {단어토큰:인덱스}로 구성된 단어사전을 가지고 있다. 이를 참조하여 토큰을 인덱스로 바꾸어준다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ACGrbSMk_g8k","executionInfo":{"status":"ok","timestamp":1606547903970,"user_tz":-540,"elapsed":45253,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"fe6237aa-247a-4a7e-933a-a7fd29d0d0ae"},"source":["#어텐션 마스크 초기화\n","attention_masks=[]\n","\n","#어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","#패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","  seq_mask=[float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2eZvZjSLBO2g","executionInfo":{"status":"ok","timestamp":1606547905531,"user_tz":-540,"elapsed":46807,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"757004e1-ad5d-455b-a86e-e88a97a49666"},"source":["#훈련셋과 검증셋으로 분리\n","train_inputs, validation_inputs, train_labels, validation_labels  = train_test_split(input_ids, labels, random_state=2018, test_size=0.1)\n","\n","# 어텐션 마스크를 훈련셋과 검증셋으로 분리\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=2018, test_size=0.1)\n","\n","# 데이터를 파이토치의 텐서로 변환\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)\t\t\t\t\n","\n","print(train_inputs[0])\n","print(train_labels[0])\n","print(train_masks[0])\n","print(validation_inputs[0])\n","print(validation_labels[0])\n","print(validation_masks[0])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tensor([   101,   9711,  11489,   9364,  41850,   9004,  32537,   9491,  35506,\n","         17360,  48549,    119,    119,   9477,  26444,  12692,   9665,  21789,\n","         11287,   9708, 119235,   9659,  22458, 119136,  12965,  48549,    119,\n","           119,   9532,  22879,   9685,  16985,  14523,  48549,    119,    119,\n","          9596, 118728,    119,    119,   9178, 106065, 118916,    119,    119,\n","          8903,  11664,  11513,   9960,  14423,  25503, 118671,  48549,    119,\n","           119,  21890,   9546,  37819,  22879,   9356,  14867,   9715, 119230,\n","        118716,  48345,    119,   9663,  23321,  10954,   9638,  35506, 106320,\n","         10739,  20173,   9359,  19105,  11102,  42428,  17196,  48549,    119,\n","           119,    100,    117,   9947,  12945,   9532,  25503,   8932,  14423,\n","         35506, 119050,  11903,  14867,  10003,  14863,  33188,  48345,    119,\n","           102,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0])\n","tensor(0)\n","tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n","        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n","tensor([   101,   1871, 111754, 111754, 111754, 111754,    102,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0,      0,      0,      0,      0,      0,      0,      0,\n","             0,      0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iyQ9WPYtCJDR","executionInfo":{"status":"ok","timestamp":1606547905533,"user_tz":-540,"elapsed":46807,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["#배치 사이즈\n","batch_size = 32\n","\n","#파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","#학습시 배치 사이즈만큼 데이터를 가져옴\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p8058mz8Cuwm"},"source":["## 테스트셋 전처리"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6VOl-_jCtY-","executionInfo":{"status":"ok","timestamp":1606547905533,"user_tz":-540,"elapsed":46801,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"dbed6a71-4f78-4917-908f-a37fdfcac147"},"source":["#리뷰 문장 추출\n","sentences = test['document']\n","sentences[:10]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0                                                  굳 ㅋ\n","1                                 GDNTOPCLASSINTHECLUB\n","2               뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n","3                     지루하지는 않은데 완전 막장임... 돈주고 보기에는....\n","4    3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??\n","5                                   음악이 주가 된, 최고의 음악영화\n","6                                              진정한 쓰레기\n","7             마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터가,고개를 젖게한다\n","8    갈수록 개판되가는 중국영화 유치하고 내용없음 폼잡다 끝남 말도안되는 무기에 유치한c...\n","9       이별의 아픔뒤에 찾아오는 새로운 인연의 기쁨 But, 모든 사람이 그렇지는 않네..\n","Name: document, dtype: object"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j5FqpdL_C9KW","executionInfo":{"status":"ok","timestamp":1606547905534,"user_tz":-540,"elapsed":46793,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"e7e07dc8-36ad-4919-a57e-9b0e053c5c32"},"source":["# BERT의 입력 형식에 맞게 변환\n","sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n","sentences[:10]"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['[CLS] 굳 ㅋ [SEP]',\n"," '[CLS] GDNTOPCLASSINTHECLUB [SEP]',\n"," '[CLS] 뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아 [SEP]',\n"," '[CLS] 지루하지는 않은데 완전 막장임... 돈주고 보기에는.... [SEP]',\n"," '[CLS] 3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠?? [SEP]',\n"," '[CLS] 음악이 주가 된, 최고의 음악영화 [SEP]',\n"," '[CLS] 진정한 쓰레기 [SEP]',\n"," '[CLS] 마치 미국애니에서 튀어나온듯한 창의력없는 로봇디자인부터가,고개를 젖게한다 [SEP]',\n"," '[CLS] 갈수록 개판되가는 중국영화 유치하고 내용없음 폼잡다 끝남 말도안되는 무기에 유치한cg남무 아 그립다 동사서독같은 영화가 이건 3류아류작이다 [SEP]',\n"," '[CLS] 이별의 아픔뒤에 찾아오는 새로운 인연의 기쁨 But, 모든 사람이 그렇지는 않네.. [SEP]']"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMNgLzylDCEY","executionInfo":{"status":"ok","timestamp":1606547905536,"user_tz":-540,"elapsed":46787,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"1cc4ad8f-3513-4bfd-848d-d4510c046984"},"source":["#라벨 추출\n","labels = test['label'].values\n","labels"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 0, 0, ..., 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z9YzTxS_DJrM","executionInfo":{"status":"ok","timestamp":1606547915305,"user_tz":-540,"elapsed":56548,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"a88a8a8b-0f9f-4950-bc8d-81a028c30177"},"source":["#BERT의 토크나이저로 문장을 토큰으로 분리\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n","\n","print(sentences[0])\n","print(tokenized_texts[0])"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[CLS] 굳 ㅋ [SEP]\n","['[CLS]', '굳', '[UNK]', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t7KF5EuCDKCQ","executionInfo":{"status":"ok","timestamp":1606547916679,"user_tz":-540,"elapsed":57914,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"2b1d6213-6309-4f59-fbfe-40ce92433c07"},"source":["#입력 토큰의 최대 시퀀스 길이\n","MAX_LEN = 128\n","\n","#토큰을 숫자 인덱스로 변환\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","#문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","input_ids[0]"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 101, 8911,  100,  102,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0])"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5pLx3F5DJ6T","executionInfo":{"status":"ok","timestamp":1606547921166,"user_tz":-540,"elapsed":62395,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"9af162cc-ae80-4708-a0fa-567b72c94560"},"source":["#어텐션 마스크 초기화\n","attention_masks=[]\n","\n","#어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","#패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","for seq in input_ids:\n","  seq_mask=[float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","\n","print(attention_masks[0])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["[1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wTUAApXRAR6P","executionInfo":{"status":"ok","timestamp":1606547921456,"user_tz":-540,"elapsed":62677,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"ae1ce62c-f0bf-45e8-91c7-4fcbceed1849"},"source":["#데이터를 파이토치의 텐서로 변환\n","test_inputs = torch.tensor(input_ids)\n","test_labels = torch.tensor(labels)\n","test_masks = torch.tensor(attention_masks)\n","\n","print(test_inputs[0])\n","print(test_labels[0])\n","print(test_masks[0])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["tensor([ 101, 8911,  100,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0])\n","tensor(1)\n","tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"teLxkKcaDgTa","executionInfo":{"status":"ok","timestamp":1606547921457,"user_tz":-540,"elapsed":62676,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["#배치 사이즈\n","batch_size = 32\n","\n","#파이토치의 DataLoader로 입력, 마스크, 라벨을 묶어 데이터 설정\n","#학습시 배치 사이즈만큼 데이터를 가져옴\n","test_data = TensorDataset(test_inputs, test_masks, test_labels)\n","test_sampler = RandomSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EyKidgD-DnE5"},"source":["##모델 생성"]},{"cell_type":"code","metadata":{"id":"MFnt7uyqD2MJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606547921458,"user_tz":-540,"elapsed":62671,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"bcff6172-5697-47f1-a939-2c680c037a74"},"source":["if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","  print(\"We will use the GPU:\", torch.cuda.get_device_name(0))"],"execution_count":23,"outputs":[{"output_type":"stream","text":["We will use the GPU: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["2342aa2bfdb9400c949c70ca55d95405","88278cffb6bf42389ca158728334e77e","03e14af30f3541b7aa6c402c14b0cbbf","4b1f456ace7b48fb88b207e809683df0","2ff4a0d6655d4bdabe6b3f9f7f9e15da","c65824a84cfc4db0ab66f523418de49a","41ee3f8dd81e491c9b2079fd3e0398d3","aab2bd2c33d949bb9dd0ef822b31328f","8d4e98c4cb574c9fb2f59ede96ae5fb2","42322deb53ce4ccbaa73f965b985de44","e041b0ca61524ada8fe8f72e46528b1c","d7550ac46fb540aaa5ae94b13ff998a9","746abdf231f54bbea35bcd63e9462f59","e4bce99aa1d848769473687a8e1238e6","c9eb6f9645e94e329df0f90a5f884d13","783a3f40c7af426db4c251c9d6cb5952"]},"id":"qF6ovUDfESQo","executionInfo":{"status":"ok","timestamp":1606548213950,"user_tz":-540,"elapsed":355158,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"771154d9-c589-4020-d3d4-fe58560ba449"},"source":["model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n","model.cuda()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2342aa2bfdb9400c949c70ca55d95405","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d4e98c4cb574c9fb2f59ede96ae5fb2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"_SIjacYzFFQZ","executionInfo":{"status":"ok","timestamp":1606554307068,"user_tz":-540,"elapsed":727,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["#옵티마이저 설정\n","optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8) #lr 학습률, eps 0으로 나누는 것을 방지하기 위한 epsilon값\n","\n","#에폭수\n","epochs = 3\n","\n","#총 훈련 스텝 : 배치반복 횟수 * 에폭\n","total_steps = len(train_dataloader) * epochs\n","\n","#학습률을 조금씩 감소시키는 스케쥴러 생성\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3nmEkUPfJkq"},"source":["## 모델 학습"]},{"cell_type":"code","metadata":{"id":"iqcD0L2TfJMS","executionInfo":{"status":"ok","timestamp":1606557920907,"user_tz":-540,"elapsed":485,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    \n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAxYDRvKF-qq","executionInfo":{"status":"ok","timestamp":1606548213957,"user_tz":-540,"elapsed":355149,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["#시간 표시 함수\n","def format_time(elapsed):\n","  elapsed_rounded = int(round((elapsed)))\n","  return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZagdbJ7vC6w-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606567041339,"user_tz":-540,"elapsed":9090827,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"59a34614-7855-4adf-dea7-d248eeb5d844"},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":33,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 3 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:46.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:32.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:18.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:03.\n","  Batch 2,500  of  4,219.    Elapsed: 0:28:48.\n","  Batch 3,000  of  4,219.    Elapsed: 0:34:34.\n","  Batch 3,500  of  4,219.    Elapsed: 0:40:19.\n","  Batch 4,000  of  4,219.    Elapsed: 0:46:04.\n","\n","  Average training loss: 0.08\n","  Training epcoh took: 0:48:35\n","\n","Running Validation...\n","  Accuracy: 0.86\n","  Validation took: 0:01:49\n","\n","======== Epoch 2 / 3 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:46.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:32.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:18.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:04.\n","  Batch 2,500  of  4,219.    Elapsed: 0:28:50.\n","  Batch 3,000  of  4,219.    Elapsed: 0:34:37.\n","  Batch 3,500  of  4,219.    Elapsed: 0:40:23.\n","  Batch 4,000  of  4,219.    Elapsed: 0:46:09.\n","\n","  Average training loss: 0.11\n","  Training epcoh took: 0:48:40\n","\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation took: 0:01:50\n","\n","======== Epoch 3 / 3 ========\n","Training...\n","  Batch   500  of  4,219.    Elapsed: 0:05:47.\n","  Batch 1,000  of  4,219.    Elapsed: 0:11:34.\n","  Batch 1,500  of  4,219.    Elapsed: 0:17:21.\n","  Batch 2,000  of  4,219.    Elapsed: 0:23:08.\n","  Batch 2,500  of  4,219.    Elapsed: 0:28:55.\n","  Batch 3,000  of  4,219.    Elapsed: 0:34:41.\n","  Batch 3,500  of  4,219.    Elapsed: 0:40:28.\n","  Batch 4,000  of  4,219.    Elapsed: 0:46:14.\n","\n","  Average training loss: 0.19\n","  Training epcoh took: 0:48:46\n","\n","Running Validation...\n","  Accuracy: 0.87\n","  Validation took: 0:01:49\n","\n","Training complete!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FSCy1nwBMOGg"},"source":["## 테스트셋 평가"]},{"cell_type":"code","metadata":{"id":"NSkR1zPDGHw8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606567050297,"user_tz":-540,"elapsed":4453,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"083fe435-88c7-4c80-8560-dc422790a84f"},"source":["#시작 시간 설정\n","t0 = time.time()\n","\n","#평가모드로 변경\n","model.eval()\n","\n","#변수 초기화\n","eval_loss, eval_accuracy = 0, 0\n","nb_eval_steps, nb_eval_examples = 0, 0\n","\n","#데이터로더에서 배치만큼 반복하여 가져옴\n","for step, batch in enumerate(test_dataloader):\n","  #경과 정보 표시\n","  if step % 100 == 0 and not step == 0:\n","    elapsed = format_time(time.time() - t0)\n","    print(\" Batch{:>5,} of {:>5,}. Elapsed: {:}.\".format(step, len(test_dataloader), elapsed))\n","\n","    #배치를 GPU에 넣음\n","    batch = tuple(t.to(device) for t in batch)\n","\n","    #배치에서 데이터 추출\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    #그래디언트 계산 안함\n","    with torch.no_grad():\n","      #Forward 수행\n","      outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","    #로스 구함\n","    logits = outputs[0]\n","\n","    #CPU로 데이터 이동\n","    logits = logits.detach().cpu().numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    #출력 로짓과 라벨을 비교하여 정확도 계산\n","    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","    eval_accuracy += tmp_eval_accuracy\n","    nb_eval_steps += 1\n","\n","print(\"\")\n","print(\" Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","print(\" Validation took: {:}\".format(format_time(time.time() - t0)))\n"],"execution_count":35,"outputs":[{"output_type":"stream","text":[" Batch  100 of 1,563. Elapsed: 0:00:00.\n"," Batch  200 of 1,563. Elapsed: 0:00:00.\n"," Batch  300 of 1,563. Elapsed: 0:00:01.\n"," Batch  400 of 1,563. Elapsed: 0:00:01.\n"," Batch  500 of 1,563. Elapsed: 0:00:01.\n"," Batch  600 of 1,563. Elapsed: 0:00:01.\n"," Batch  700 of 1,563. Elapsed: 0:00:02.\n"," Batch  800 of 1,563. Elapsed: 0:00:02.\n"," Batch  900 of 1,563. Elapsed: 0:00:02.\n"," Batch1,000 of 1,563. Elapsed: 0:00:02.\n"," Batch1,100 of 1,563. Elapsed: 0:00:03.\n"," Batch1,200 of 1,563. Elapsed: 0:00:03.\n"," Batch1,300 of 1,563. Elapsed: 0:00:03.\n"," Batch1,400 of 1,563. Elapsed: 0:00:03.\n"," Batch1,500 of 1,563. Elapsed: 0:00:04.\n","\n"," Accuracy: 0.89\n"," Validation took: 0:00:04\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OOSkZYM2bAvc"},"source":["Utilize to HMG"]},{"cell_type":"code","metadata":{"id":"UOTXS8hYaS7a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606567054366,"user_tz":-540,"elapsed":864,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"39eb095c-3e24-451c-df7f-850e4c1595dc"},"source":["!ls"],"execution_count":36,"outputs":[{"output_type":"stream","text":["matge.csv  nsmc  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JGZd87Y0acll","executionInfo":{"status":"ok","timestamp":1606567057799,"user_tz":-540,"elapsed":769,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["import pandas as pd\n","import numpy as np\n","\n","df_raw = pd.read_csv(\"matge.csv\", encoding=\"cp949\")"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"sbOY8g9IaTwE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606567060333,"user_tz":-540,"elapsed":777,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"22464d61-07fb-4857-fa7c-5753edb43ee6"},"source":["df_raw.info"],"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method DataFrame.info of           식당명                                              리뷰 문장\n","0     레스토랑 아진                        연남동쪽에 있고 파스타 1.5 부채살 스테끼3.4\n","1     레스토랑 아진                 와인까지 세트로 5.4 저 감자 뭐시기는 0.5 레몬맛+소금맛\n","2     레스토랑 아진  알리오올리오인데 우리가 흔히 먹는 맛은 아니고 뭔가 치즈맛인가 맛표현 어려운데 맛있...\n","3     레스토랑 아진  스테끼는 뭐 당근퓨레랑 저 풀때기 뭔지 모르는데 같이 샥 해먹으면 아주 부드러움. ...\n","4     레스토랑 아진  남친이랑 100일 기념으로 갔는데 예약을 많이 하고 가는 듯. 예약 선입금 2만원 ...\n","...       ...                                                ...\n","5304      NaN                                                NaN\n","5305      NaN                                          재방문 의사 있음\n","5306      NaN                                                NaN\n","5307      NaN                 (기본토스트보다는 돈 조금 보태서 햄이나 베이컨들어간걸 추천)\n","5308      NaN                                               ]\"[\"\n","\n","[5309 rows x 2 columns]>"]},"metadata":{"tags":[]},"execution_count":38}]},{"cell_type":"code","metadata":{"id":"yM6aVh8vaise","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1606567065011,"user_tz":-540,"elapsed":744,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"f7589b50-77d5-4931-eac0-a7a4c1f126f7"},"source":["df_raw.sample(10)"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>식당명</th>\n","      <th>리뷰 문장</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5023</th>\n","      <td>당인동 국수공장</td>\n","      <td>ㅡ넒음</td>\n","    </tr>\n","    <tr>\n","      <th>1001</th>\n","      <td>정문 앞 롤링파스타</td>\n","      <td>다른 지점보다 가지라던지 재료가 조금 덜 들어있었지만</td>\n","    </tr>\n","    <tr>\n","      <th>3692</th>\n","      <td>홍아지트</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1964</th>\n","      <td>플라워</td>\n","      <td>그리고 화장실이 깨끗하다!! &amp;lt;- 중요</td>\n","    </tr>\n","    <tr>\n","      <th>2110</th>\n","      <td>베리메리</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3941</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1319</th>\n","      <td>NaN</td>\n","      <td>]\"[\"</td>\n","    </tr>\n","    <tr>\n","      <th>4940</th>\n","      <td>오키나와루</td>\n","      <td>김부각에 와사비를 섞었는데 달아진 맛</td>\n","    </tr>\n","    <tr>\n","      <th>1921</th>\n","      <td>시즌샌드위치</td>\n","      <td>진짜 맛있었음</td>\n","    </tr>\n","    <tr>\n","      <th>2987</th>\n","      <td>합정 소문</td>\n","      <td>깔끔하니 맛있음! 부드럽고 소스 맛있음. 긁어먹음.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             식당명                          리뷰 문장\n","5023    당인동 국수공장                            ㅡ넒음\n","1001  정문 앞 롤링파스타  다른 지점보다 가지라던지 재료가 조금 덜 들어있었지만\n","3692        홍아지트                            NaN\n","1964         플라워       그리고 화장실이 깨끗하다!! &lt;- 중요\n","2110        베리메리                            NaN\n","3941         NaN                            NaN\n","1319         NaN                           ]\"[\"\n","4940       오키나와루           김부각에 와사비를 섞었는데 달아진 맛\n","1921      시즌샌드위치                        진짜 맛있었음\n","2987       합정 소문   깔끔하니 맛있음! 부드럽고 소스 맛있음. 긁어먹음."]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"MeWgzqwEakOo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606567071452,"user_tz":-540,"elapsed":739,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"67330561-ea3b-4b3b-d67a-06b599b022e3"},"source":["df_raw.isnull().sum()"],"execution_count":40,"outputs":[{"output_type":"execute_result","data":{"text/plain":["식당명      1048\n","리뷰 문장    1381\n","dtype: int64"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"3CYS0KNvalLF","executionInfo":{"status":"ok","timestamp":1606567074648,"user_tz":-540,"elapsed":833,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["df_dropped = df_raw.dropna(axis=0)"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"ajoQ4HXoamGE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606567077346,"user_tz":-540,"elapsed":752,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"638dd134-0d3f-40b0-ec13-4fcf1c96f02d"},"source":["df_dropped.info()"],"execution_count":42,"outputs":[{"output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","Int64Index: 3298 entries, 0 to 5291\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype \n","---  ------  --------------  ----- \n"," 0   식당명     3298 non-null   object\n"," 1   리뷰 문장   3298 non-null   object\n","dtypes: object(2)\n","memory usage: 77.3+ KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vKfB-Tqranim","colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"status":"ok","timestamp":1606567080118,"user_tz":-540,"elapsed":705,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"4d4db40b-8c92-4c67-fdbd-d10f15e7d3f7"},"source":["df_dropped.sample(10)"],"execution_count":43,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>식당명</th>\n","      <th>리뷰 문장</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2732</th>\n","      <td>다디치 커피</td>\n","      <td>맨날 사람 없어서 사라질까봐 올림... 아저씨 아주머니 엄청 착하시고 친절하심 그리...</td>\n","    </tr>\n","    <tr>\n","      <th>4183</th>\n","      <td>힙정옥</td>\n","      <td>곰탕하면 '하동관'이라는 노포를 떠올리게 되는데, 저는 이제 합정옥을 더 많이 가게...</td>\n","    </tr>\n","    <tr>\n","      <th>290</th>\n","      <td>연남물갈비</td>\n","      <td>저 야채 속에 등갈비 있는데 연해서 맛있더라</td>\n","    </tr>\n","    <tr>\n","      <th>1349</th>\n","      <td>호호미역 홍대점</td>\n","      <td>사장님 들어갈때 반갑게 맞아주시고</td>\n","    </tr>\n","    <tr>\n","      <th>3060</th>\n","      <td>신선마라탕</td>\n","      <td>빽다방 골목쪽에 있는 신선 마라탕 지금 50% 할인합니다!! 많이 와주세요ㅠㅠㅠ 원...</td>\n","    </tr>\n","    <tr>\n","      <th>1356</th>\n","      <td>호호미역 홍대점</td>\n","      <td>미리 볶아둔게 아니라 주문들어가고 나서 볶기 시작하셨음. 천원짜리 반찬 포장도 따로...</td>\n","    </tr>\n","    <tr>\n","      <th>3460</th>\n","      <td>퍼센테지</td>\n","      <td>퍼센테지 오레오스무디 먹으러갔는데 카페 임대하더라ㅜㅜ</td>\n","    </tr>\n","    <tr>\n","      <th>2385</th>\n","      <td>상수 비스트로보이</td>\n","      <td>연어로제파스타 8500 / 불고기뚝배기파스타 8900</td>\n","    </tr>\n","    <tr>\n","      <th>3588</th>\n","      <td>고토히라 우동</td>\n","      <td>메뉴:  키노코 우동</td>\n","    </tr>\n","    <tr>\n","      <th>3397</th>\n","      <td>연남동 감칠</td>\n","      <td>분위기도 좋고 가성비도 갠츈갠츈!!</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            식당명                                              리뷰 문장\n","2732     다디치 커피  맨날 사람 없어서 사라질까봐 올림... 아저씨 아주머니 엄청 착하시고 친절하심 그리...\n","4183        힙정옥  곰탕하면 '하동관'이라는 노포를 떠올리게 되는데, 저는 이제 합정옥을 더 많이 가게...\n","290       연남물갈비                           저 야채 속에 등갈비 있는데 연해서 맛있더라\n","1349   호호미역 홍대점                                사장님 들어갈때 반갑게 맞아주시고 \n","3060      신선마라탕  빽다방 골목쪽에 있는 신선 마라탕 지금 50% 할인합니다!! 많이 와주세요ㅠㅠㅠ 원...\n","1356   호호미역 홍대점  미리 볶아둔게 아니라 주문들어가고 나서 볶기 시작하셨음. 천원짜리 반찬 포장도 따로...\n","3460       퍼센테지                      퍼센테지 오레오스무디 먹으러갔는데 카페 임대하더라ㅜㅜ\n","2385  상수 비스트로보이                      연어로제파스타 8500 / 불고기뚝배기파스타 8900\n","3588    고토히라 우동                                        메뉴:  키노코 우동\n","3397     연남동 감칠                               분위기도 좋고 가성비도 갠츈갠츈!! "]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"01Carm9OapUm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606567083786,"user_tz":-540,"elapsed":741,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"ffb52be9-4fdc-4974-884c-9f6e4429e517"},"source":["df_dropped['리뷰 문장'] = df_dropped['리뷰 문장'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣|0-9 ]\",\"\")"],"execution_count":44,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"YiLo1Oweaqo-","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"ok","timestamp":1606567086892,"user_tz":-540,"elapsed":708,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"2a2a24f4-80b0-467a-f829-5b9e15f46b3d"},"source":["df_dropped.sample(10)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>식당명</th>\n","      <th>리뷰 문장</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4166</th>\n","      <td>홍대 수카츠</td>\n","      <td>직원들은 친절했음</td>\n","    </tr>\n","    <tr>\n","      <th>182</th>\n","      <td>망원 멘지</td>\n","      <td>최고의 맛</td>\n","    </tr>\n","    <tr>\n","      <th>3379</th>\n","      <td>북촌손만두</td>\n","      <td>오늘 북촌손만두에서 육개장 먹었는데요 이 오른쪽 무 한조각이 나와서 사장님은 국물낼...</td>\n","    </tr>\n","    <tr>\n","      <th>3362</th>\n","      <td>홍대 우산</td>\n","      <td>홍대 7출 앞쪽 도보 2분 이층 버거집 올드루키스버거</td>\n","    </tr>\n","    <tr>\n","      <th>1823</th>\n","      <td>더피자보이즈</td>\n","      <td>그래도 피자먹고싶을때 또 갈거임</td>\n","    </tr>\n","    <tr>\n","      <th>1101</th>\n","      <td>요요스시</td>\n","      <td>합정역 5번 출구 근처에 있는 요요스시임</td>\n","    </tr>\n","    <tr>\n","      <th>2806</th>\n","      <td>북창동순두부</td>\n","      <td>저번에도 그 아주머니 불친절하셔서 좀 짜증났었는데 덕분에 갈일이 더블로 없어졌네용</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>칸다소바</td>\n","      <td>마제소바 9500원</td>\n","    </tr>\n","    <tr>\n","      <th>1070</th>\n","      <td>짱주먹밥</td>\n","      <td>날치알 3000원 계란후라이 800원</td>\n","    </tr>\n","    <tr>\n","      <th>3891</th>\n","      <td>춘리 슈가 흑당 버블티</td>\n","      <td>춘리 슈가 흑당 버블티 새로 오픈했는데 오픈할인해서 4700원 비싸긴한데</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["               식당명                                              리뷰 문장\n","4166        홍대 수카츠                                          직원들은 친절했음\n","182          망원 멘지                                             최고의 맛 \n","3379         북촌손만두  오늘 북촌손만두에서 육개장 먹었는데요 이 오른쪽 무 한조각이 나와서 사장님은 국물낼...\n","3362         홍대 우산                      홍대 7출 앞쪽 도보 2분 이층 버거집 올드루키스버거\n","1823        더피자보이즈                                  그래도 피자먹고싶을때 또 갈거임\n","1101          요요스시                             합정역 5번 출구 근처에 있는 요요스시임\n","2806        북창동순두부      저번에도 그 아주머니 불친절하셔서 좀 짜증났었는데 덕분에 갈일이 더블로 없어졌네용\n","15            칸다소바                                         마제소바 9500원\n","1070          짱주먹밥                               날치알 3000원 계란후라이 800원\n","3891  춘리 슈가 흑당 버블티          춘리 슈가 흑당 버블티 새로 오픈했는데 오픈할인해서 4700원 비싸긴한데 "]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"40Tim7ODwifq","executionInfo":{"status":"ok","timestamp":1606567128571,"user_tz":-540,"elapsed":702,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["def convert_input_data(sentences):\n","\n","  #BERT의 토크나이저로 문장을 토큰으로 분리\n","  tokenized_texts = [tokenizer.tokenize(sen) for sen in sentences]\n","\n","  #입력 토큰의 최대 시퀀스 길이\n","  MAX_LEN = 128\n","\n","  #토큰을 숫자 인덱스로 변환\n","  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","\n","  #문장을 MAX_LEN 길이에 맞게 자르고, 모자란 부분을 패딩 0으로 채움\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","  #어텐션 마스크 초기화\n","  attention_masks = []\n","\n","  #어텐션 마스크를 패딩이 아니면 1, 패딩이면 0으로 설정\n","  #패딩 부분은 BERT 모델에서 어텐션을 수행하지 않아 속도 향상\n","  for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","\n","  #데이터를 파이토치의 텐서로 변환\n","  inputs = torch.tensor(input_ids)\n","  masks = torch.tensor(attention_masks)\n","\n","  return inputs, masks"],"execution_count":47,"outputs":[]},{"cell_type":"code","metadata":{"id":"d1lw9P_9y9rY","executionInfo":{"status":"ok","timestamp":1606567138261,"user_tz":-540,"elapsed":785,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["def test_sentences(sentences):\n","  \n","  #평가모드로 변경\n","  model.eval()\n","\n","  #문장을 입력 데이터로 변환\n","  inputs, masks = convert_input_data(sentences)\n","\n","  #데이터를 GPU에 넣음\n","  b_input_ids = inputs.to(device)\n","  b_input_mask = masks.to(device)\n","\n","  #그래디언트 계산 안함\n","  with torch.no_grad():\n","    #Forward 수행\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","\n","  #로스 구함\n","  logits = outputs[0]\n","\n","  #CPU로 데이터 이동\n","  logits = logits.detach().cpu().numpy()\n","\n","  return logits"],"execution_count":48,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rl2ToyPTzrGA","executionInfo":{"status":"ok","timestamp":1606567143902,"user_tz":-540,"elapsed":767,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"6d43b00f-92a5-4283-dd23-3deb0f7846c3"},"source":["logits = test_sentences([\"연기는 별로지만 재미 하나는 끝내줌!\"])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":49,"outputs":[{"output_type":"stream","text":["[[-3.047224   3.0989723]]\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKXDw36mz13k","executionInfo":{"status":"ok","timestamp":1606567150123,"user_tz":-540,"elapsed":867,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"a8e9c763-1672-47a0-b593-80286483d1a9"},"source":["logits = test_sentences([\"이딴게 영화냐 ㅉㅉ\"])\n","\n","print(logits)\n","print(np.argmax(logits))"],"execution_count":50,"outputs":[{"output_type":"stream","text":["[[ 3.3799307 -3.0779366]]\n","0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NInRAnMLz50J","executionInfo":{"status":"ok","timestamp":1606567155101,"user_tz":-540,"elapsed":1147,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["#0은 부정 1은 긍정\n","def good_or_bad(sentence):\n","  logits = test_sentences([sentence])\n","  determine = np.argmax(logits)\n","  \n","  return determine"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ps2_sZfU0MR7","executionInfo":{"status":"ok","timestamp":1606567157451,"user_tz":-540,"elapsed":858,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"c45d8919-52be-49f6-faf6-2744618f63c3"},"source":["#극찬 영화평 BERT로 확인해보기\n","good_or_bad(\"와 개쩐다 정말 세계관 최강자들의 영화다\")"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"code","metadata":{"id":"_h9jxKRN0TOg","executionInfo":{"status":"ok","timestamp":1606567200146,"user_tz":-540,"elapsed":729,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["#리뷰 라벨링\n","def label_review_bert(series_object):\n","  list_scores=[]\n","  list_reviews = series_object.to_list()\n","  for item in list_reviews:\n","    score = good_or_bad(item)\n","    list_scores.append(score)\n","  return list_scores"],"execution_count":53,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KxB_FW5T0pKt","executionInfo":{"status":"ok","timestamp":1606567244515,"user_tz":-540,"elapsed":42395,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"c5327cf0-8347-4e86-81d5-a3c41e121c22"},"source":["df_dropped[\"BERT_SCORE\"] = label_review_bert(df_dropped[\"리뷰 문장\"]) "],"execution_count":54,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"id":"rxoCVFO61T7D","executionInfo":{"status":"ok","timestamp":1606567247056,"user_tz":-540,"elapsed":806,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}},"outputId":"025693d4-f5cc-495b-c8a8-c5b99b6e9d74"},"source":["df_dropped.sample(10)"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>식당명</th>\n","      <th>리뷰 문장</th>\n","      <th>BERT_SCORE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1569</th>\n","      <td>마코토</td>\n","      <td>더밥때부터 종종 가던 가게인데 마코토로 옮기고도 연어덮밥 땡길때 갑니다 ㅎㅎ</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2203</th>\n","      <td>진만두</td>\n","      <td>산울림 소극장 삼거리 안쪽에 위치한 만두가게 전통 중국식 만두를 판다 가성비는 다른...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4537</th>\n","      <td>더리터</td>\n","      <td>먹는것을추천함</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4696</th>\n","      <td>홍커피</td>\n","      <td>홍커피 딸바 2500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2685</th>\n","      <td>보물섬식당</td>\n","      <td>오늘 점심은  돈까스각이었다</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3667</th>\n","      <td>친구네집빈날</td>\n","      <td>사진 속 칵테일은 미도리샤워 칵테일도 이뻐서 추천</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3010</th>\n","      <td>상수 미쁘다</td>\n","      <td>존나 맛있다</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3748</th>\n","      <td>짬뽕지존</td>\n","      <td>ㅡ여기서 짬뽕을먹어도되나 싶은 궁전</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>299</th>\n","      <td>연남물갈비</td>\n","      <td>글구 일회용 앞치마도 부족했어 뭔가 재고관리 능력이 안타깝더라</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>고피자 상수점</td>\n","      <td>맛없는데 파스타 두개에 5500원이라 저렴한 맛에는 먹을만 함</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          식당명                                              리뷰 문장  BERT_SCORE\n","1569      마코토         더밥때부터 종종 가던 가게인데 마코토로 옮기고도 연어덮밥 땡길때 갑니다 ㅎㅎ           1\n","2203      진만두  산울림 소극장 삼거리 안쪽에 위치한 만두가게 전통 중국식 만두를 판다 가성비는 다른...           1\n","4537      더리터                                            먹는것을추천함           1\n","4696      홍커피                                        홍커피 딸바 2500           0\n","2685    보물섬식당                                   오늘 점심은  돈까스각이었다            0\n","3667   친구네집빈날                        사진 속 칵테일은 미도리샤워 칵테일도 이뻐서 추천           1\n","3010   상수 미쁘다                                             존나 맛있다           1\n","3748     짬뽕지존                                ㅡ여기서 짬뽕을먹어도되나 싶은 궁전           1\n","299     연남물갈비                 글구 일회용 앞치마도 부족했어 뭔가 재고관리 능력이 안타깝더라           0\n","123   고피자 상수점                 맛없는데 파스타 두개에 5500원이라 저렴한 맛에는 먹을만 함           0"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"o7WYfDor1WWh","executionInfo":{"status":"ok","timestamp":1606567261178,"user_tz":-540,"elapsed":844,"user":{"displayName":"고민재","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgSRd50JrzgnT4ykT5ovjqlCoGm2nQIK4GphkJrhA=s64","userId":"07742128302127648757"}}},"source":["df_dropped.to_csv(f\"HMG_Sentiment_Analysis_BERT.csv\",encoding=\"cp949\")"],"execution_count":56,"outputs":[]},{"cell_type":"code","metadata":{"id":"nR-TiPqi1sFR"},"source":[""],"execution_count":null,"outputs":[]}]}